# Full Local Mode Testing

This directory contains tests for the Full Local Mode feature, which allows Auto-Claude to run entirely on local Ollama models without using Claude API.

## Quick Start (Windows)

### 1. Install Ollama

Download and install from: https://ollama.com/download

### 2. Install Recommended Models

Open PowerShell or Command Prompt:

```powershell
ollama pull llama3.2:3b
ollama pull llama3.1:8b
ollama pull qwen2.5-coder:7b
```

### 3. Install Python Dependencies

```powershell
cd C:\Users\<YourUsername>\Documents\HybridCoder\Auto-Claude
pip install requests
```

### 4. Run the Test Script

```powershell
python tests\test_full_local_mode.py
```

## Quick Start (Linux/Mac)

### 1. Install Ollama

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

### 2. Install Recommended Models

```bash
ollama pull llama3.2:3b
ollama pull llama3.1:8b
ollama pull qwen2.5-coder:7b
```

### 3. Install Python Dependencies

```bash
cd ~/Auto-Claude
pip3 install requests
```

### 4. Run the Test Script

```bash
python3 tests/test_full_local_mode.py
```

## What the Test Checks

The test script verifies:

- ‚úÖ Ollama service is running
- ‚úÖ Recommended models are installed
- ‚úÖ Settings file exists
- ‚úÖ Full Local Mode is configured
- ‚úÖ Models are set to Ollama (not Claude)
- ‚úÖ Backend functions work correctly

## Expected Output

```
============================================================
              Full Local Mode Test Suite
============================================================

‚ÑπÔ∏è  Platform: nt (Windows)
‚ÑπÔ∏è  Config directory: C:\Users\Marc\AppData\Roaming\auto-claude

üß™ Testing: Ollama Service Running
‚úÖ Ollama is running with 3 models

üß™ Testing: Ollama Models Installed
‚úÖ Model llama3.2:3b is installed
‚úÖ Model llama3.1:8b is installed
‚úÖ Model qwen2.5-coder:7b is installed

üß™ Testing: Settings File Exists
‚úÖ Settings file found: C:\Users\Marc\AppData\Roaming\auto-claude\settings.json

üß™ Testing: Full Local Mode Configuration
‚úÖ Full Local Mode is ENABLED
‚ÑπÔ∏è  Using Smart Auto-Select

üß™ Testing: Model Configuration
‚úÖ Phase 'spec' uses Ollama: ollama:llama3.1:8b
‚úÖ Phase 'planning' uses Ollama: ollama:llama3.1:8b
‚úÖ Phase 'coding' uses Ollama: ollama:qwen2.5-coder:7b
‚úÖ Phase 'qa' uses Ollama: ollama:llama3.1:8b

üß™ Testing: Backend Phase Configuration
‚úÖ is_ollama_model() correctly identifies: ollama:llama3.1:8b
‚úÖ get_ollama_model_name() returns: llama3.1:8b
‚úÖ resolve_model_id() preserves ollama: prefix

üß™ Testing: Ollama Client
‚úÖ OllamaClient can be imported
‚úÖ OllamaClient instance created

============================================================
                      Test Summary
============================================================

Total Tests: 15
Passed: 15
Failed: 0

üéâ All tests passed! Full Local Mode is ready to use.
```

## Troubleshooting

### Ollama Not Running

**Windows:**
```powershell
# Start Ollama
ollama serve
```

**Linux:**
```bash
sudo systemctl start ollama
```

### Model Not Found

```bash
# List installed models
ollama list

# Install missing model
ollama pull llama3.1:8b
```

### Settings File Not Found

Run Auto-Claude at least once to create the settings file:

1. Open Auto-Claude
2. Go to Settings
3. Close Auto-Claude
4. Run the test again

### Import Errors

Make sure you're running the test from the Auto-Claude root directory:

```powershell
# Windows
cd C:\Users\<YourUsername>\Documents\HybridCoder\Auto-Claude
python tests\test_full_local_mode.py

# Linux/Mac
cd ~/Auto-Claude
python3 tests/test_full_local_mode.py
```

## Manual Testing

For comprehensive manual testing, see: [Full Local Mode Testing Guide](../docs/FULL_LOCAL_MODE_TESTING.md)

## Configuration Locations

### Windows
- Settings: `%APPDATA%\auto-claude\settings.json`
- Logs: `%USERPROFILE%\.auto-claude\logs\`

### Linux/Mac
- Settings: `~/.config/auto-claude/settings.json`
- Logs: `~/.auto-claude/logs/`

## Support

If tests fail:

1. Check Ollama is running: `http://localhost:11434`
2. Check logs: `%USERPROFILE%\.auto-claude\logs\backend.log`
3. Enable debug mode in Settings
4. Create a GitHub issue with test output

## Related Files

- `test_full_local_mode.py` - Automated test script
- `test_hybrid_provider.py` - Tests for hybrid provider
- `test_context_optimizer.py` - Tests for context optimization
